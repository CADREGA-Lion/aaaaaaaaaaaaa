{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv3LfLZOooMCVGenTLq+fR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CADREGA-Lion/aaaaaaaaaaaaa/blob/main/metodo%20ricerca%20file\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUHc5xJxk5aW",
        "outputId": "3dfd9d4c-a0d8-421e-96a3-a8fcb5b0e041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h[INFO] Scarico con gdown usando FOLDER_ID...\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Retrieving folder contents\n",
            "Processing file 1qMjzuW9wIqR6PsLgCz6i7l77VjLzVaFd 01-Introduzione.pdf\n",
            "Processing file 1PhB3zXa6MhvZ9EUa3kL1IB8F7vN_lZJr 02-ListaSimboli.pdf\n",
            "Processing file 1kZBEk31IiVBqVcuKZfAun54McXgW0bti 03-Lezione1-NumeriFiniti.pdf\n",
            "Processing file 1VAtqX-FNj3oE4GgP6UEcg7USJgikSB8P 04-Lezione2-IntroMatlab.pdf\n",
            "Processing file 1ARUahkhU_x18kH3azjgwH3OIHZ3N_aB9 05-Lezione3-PuntofisBisezNewton.pdf\n",
            "Processing file 1x4Q52NXh35kOnzQ0NFd1b-RP28qAvKDD 06-Ripasso-I-Matrici.pdf\n",
            "Processing file 1qa2ddA8XbL2YA8BbDAuE842VPnior4DM 07-Lezione4-ArrayFunctionSucces.pdf\n",
            "Processing file 1T9Exq76LTTjYVjJHyXeTsIitTUtLA2r6 08-Ripasso-II-Matrici.pdf\n",
            "Processing file 1jAeQbUyAnS38fxtLTTxg0RFhi9eq5_3w 09-Lezione5-NormCondSistSempl.pdf\n",
            "Processing file 1ElgLQJLp9JrsI7YRSPMI5NaQ3UGnVMeE 10-Lezione6-Gauss.pdf\n",
            "Processing file 1F6OtEeDZXEBEa4iSzo8LAodCiidZYpqY 11-Lezione7-QR.pdf\n",
            "Processing file 1iQqUM3g_LO39KNeIIoAPn2SA9xptjL5a 12-Ripasso-III-Matrici.pdf\n",
            "Processing file 1dEcAuOVms5IYuy_p3vrzmoeSio1Wzsoh 13-Lezione8-PotQRiter.pdf\n",
            "Processing file 1yQHYXavwL1Vjfq9L5JX6TyNEAEot35Px 14-Lezione9-JacGasNewtonSistemi.pdf\n",
            "Processing file 1Ewb2l_K3DcQzNuhBGn_AmSRqmOSbD9O6 15-Ripasso-ODE.pdf\n",
            "Processing file 1RNyPjxvxX-bgWYxWEwNJMmHvjWLgiGTJ 16-Lezione10-MatlabAlgLin.pdf\n",
            "Processing file 1ACYmSisDZBizT7F9BR_6SZXFxTsS0E6O 17-Lezione11-InterpAppros.pdf\n",
            "Processing file 1CzEYYfRuQlX_zkdTA76kppUuYlQqy1ty 18-Lezione12-DerivaIntegra.pdf\n",
            "Processing file 1aqjme2vv4nhPu5fG2D-v7G_M_nnT3aIu 19-Lezione13-Spline.pdf\n",
            "Processing file 1oT6hygvb8s08wpfVLhQmvbLMbVKECf0V 20-Lezione14-MatlabInterpAppros.pdf\n",
            "Processing file 1Cq8Wrq9g-Nh-HeYIN_H8t49RDKbHdzHl 21-Lezione15-ODEivp.pdf\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qMjzuW9wIqR6PsLgCz6i7l77VjLzVaFd\n",
            "To: /content/input_pdfs/01-Introduzione.pdf\n",
            "100% 94.9k/94.9k [00:00<00:00, 74.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PhB3zXa6MhvZ9EUa3kL1IB8F7vN_lZJr\n",
            "To: /content/input_pdfs/02-ListaSimboli.pdf\n",
            "100% 105k/105k [00:00<00:00, 83.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kZBEk31IiVBqVcuKZfAun54McXgW0bti\n",
            "To: /content/input_pdfs/03-Lezione1-NumeriFiniti.pdf\n",
            "100% 397k/397k [00:00<00:00, 89.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VAtqX-FNj3oE4GgP6UEcg7USJgikSB8P\n",
            "To: /content/input_pdfs/04-Lezione2-IntroMatlab.pdf\n",
            "100% 404k/404k [00:00<00:00, 97.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ARUahkhU_x18kH3azjgwH3OIHZ3N_aB9\n",
            "To: /content/input_pdfs/05-Lezione3-PuntofisBisezNewton.pdf\n",
            "100% 1.85M/1.85M [00:00<00:00, 157MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x4Q52NXh35kOnzQ0NFd1b-RP28qAvKDD\n",
            "To: /content/input_pdfs/06-Ripasso-I-Matrici.pdf\n",
            "100% 284k/284k [00:00<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qa2ddA8XbL2YA8BbDAuE842VPnior4DM\n",
            "To: /content/input_pdfs/07-Lezione4-ArrayFunctionSucces.pdf\n",
            "100% 542k/542k [00:00<00:00, 88.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T9Exq76LTTjYVjJHyXeTsIitTUtLA2r6\n",
            "To: /content/input_pdfs/08-Ripasso-II-Matrici.pdf\n",
            "100% 796k/796k [00:00<00:00, 110MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jAeQbUyAnS38fxtLTTxg0RFhi9eq5_3w\n",
            "To: /content/input_pdfs/09-Lezione5-NormCondSistSempl.pdf\n",
            "100% 433k/433k [00:00<00:00, 99.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ElgLQJLp9JrsI7YRSPMI5NaQ3UGnVMeE\n",
            "To: /content/input_pdfs/10-Lezione6-Gauss.pdf\n",
            "100% 500k/500k [00:00<00:00, 143MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1F6OtEeDZXEBEa4iSzo8LAodCiidZYpqY\n",
            "To: /content/input_pdfs/11-Lezione7-QR.pdf\n",
            "100% 435k/435k [00:00<00:00, 89.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iQqUM3g_LO39KNeIIoAPn2SA9xptjL5a\n",
            "To: /content/input_pdfs/12-Ripasso-III-Matrici.pdf\n",
            "100% 313k/313k [00:00<00:00, 82.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dEcAuOVms5IYuy_p3vrzmoeSio1Wzsoh\n",
            "To: /content/input_pdfs/13-Lezione8-PotQRiter.pdf\n",
            "100% 496k/496k [00:00<00:00, 95.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yQHYXavwL1Vjfq9L5JX6TyNEAEot35Px\n",
            "To: /content/input_pdfs/14-Lezione9-JacGasNewtonSistemi.pdf\n",
            "100% 675k/675k [00:00<00:00, 128MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ewb2l_K3DcQzNuhBGn_AmSRqmOSbD9O6\n",
            "To: /content/input_pdfs/15-Ripasso-ODE.pdf\n",
            "100% 408k/408k [00:00<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RNyPjxvxX-bgWYxWEwNJMmHvjWLgiGTJ\n",
            "To: /content/input_pdfs/16-Lezione10-MatlabAlgLin.pdf\n",
            "100% 592k/592k [00:00<00:00, 65.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ACYmSisDZBizT7F9BR_6SZXFxTsS0E6O\n",
            "To: /content/input_pdfs/17-Lezione11-InterpAppros.pdf\n",
            "100% 499k/499k [00:00<00:00, 141MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CzEYYfRuQlX_zkdTA76kppUuYlQqy1ty\n",
            "To: /content/input_pdfs/18-Lezione12-DerivaIntegra.pdf\n",
            "100% 381k/381k [00:00<00:00, 134MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aqjme2vv4nhPu5fG2D-v7G_M_nnT3aIu\n",
            "To: /content/input_pdfs/19-Lezione13-Spline.pdf\n",
            "100% 407k/407k [00:00<00:00, 53.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oT6hygvb8s08wpfVLhQmvbLMbVKECf0V\n",
            "To: /content/input_pdfs/20-Lezione14-MatlabInterpAppros.pdf\n",
            "100% 627k/627k [00:00<00:00, 94.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cq8Wrq9g-Nh-HeYIN_H8t49RDKbHdzHl\n",
            "To: /content/input_pdfs/21-Lezione15-ODEivp.pdf\n",
            "100% 1.34M/1.34M [00:00<00:00, 81.0MB/s]\n",
            "Download completed\n",
            "\n",
            "[CHECK] Contenuto scaricato (prime 100 righe):\n",
            "/content/input_pdfs:\n",
            "01-Introduzione.pdf\n",
            "02-ListaSimboli.pdf\n",
            "03-Lezione1-NumeriFiniti.pdf\n",
            "04-Lezione2-IntroMatlab.pdf\n",
            "05-Lezione3-PuntofisBisezNewton.pdf\n",
            "06-Ripasso-I-Matrici.pdf\n",
            "07-Lezione4-ArrayFunctionSucces.pdf\n",
            "08-Ripasso-II-Matrici.pdf\n",
            "09-Lezione5-NormCondSistSempl.pdf\n",
            "10-Lezione6-Gauss.pdf\n",
            "11-Lezione7-QR.pdf\n",
            "12-Ripasso-III-Matrici.pdf\n",
            "13-Lezione8-PotQRiter.pdf\n",
            "14-Lezione9-JacGasNewtonSistemi.pdf\n",
            "15-Ripasso-ODE.pdf\n",
            "16-Lezione10-MatlabAlgLin.pdf\n",
            "17-Lezione11-InterpAppros.pdf\n",
            "18-Lezione12-DerivaIntegra.pdf\n",
            "19-Lezione13-Spline.pdf\n",
            "20-Lezione14-MatlabInterpAppros.pdf\n",
            "21-Lezione15-ODEivp.pdf\n",
            "[CHECK] PDF_DIR: /content/input_pdfs\n",
            "[CHECK] PDF trovati: 21\n",
            " - /content/input_pdfs/01-Introduzione.pdf\n",
            " - /content/input_pdfs/02-ListaSimboli.pdf\n",
            " - /content/input_pdfs/03-Lezione1-NumeriFiniti.pdf\n",
            " - /content/input_pdfs/04-Lezione2-IntroMatlab.pdf\n",
            " - /content/input_pdfs/05-Lezione3-PuntofisBisezNewton.pdf\n",
            " - /content/input_pdfs/06-Ripasso-I-Matrici.pdf\n",
            " - /content/input_pdfs/07-Lezione4-ArrayFunctionSucces.pdf\n",
            " - /content/input_pdfs/08-Ripasso-II-Matrici.pdf\n",
            " - /content/input_pdfs/09-Lezione5-NormCondSistSempl.pdf\n",
            " - /content/input_pdfs/10-Lezione6-Gauss.pdf\n",
            "[INFO] Trovati 21 PDF in: /content/input_pdfs\n",
            "- (1/21) Indicizzo: 01-Introduzione.pdf\n",
            "- (2/21) Indicizzo: 02-ListaSimboli.pdf\n",
            "- (3/21) Indicizzo: 03-Lezione1-NumeriFiniti.pdf\n",
            "- (4/21) Indicizzo: 04-Lezione2-IntroMatlab.pdf\n",
            "- (5/21) Indicizzo: 05-Lezione3-PuntofisBisezNewton.pdf\n",
            "- (6/21) Indicizzo: 06-Ripasso-I-Matrici.pdf\n",
            "- (7/21) Indicizzo: 07-Lezione4-ArrayFunctionSucces.pdf\n",
            "- (8/21) Indicizzo: 08-Ripasso-II-Matrici.pdf\n",
            "- (9/21) Indicizzo: 09-Lezione5-NormCondSistSempl.pdf\n",
            "- (10/21) Indicizzo: 10-Lezione6-Gauss.pdf\n",
            "- (11/21) Indicizzo: 11-Lezione7-QR.pdf\n",
            "- (12/21) Indicizzo: 12-Ripasso-III-Matrici.pdf\n",
            "- (13/21) Indicizzo: 13-Lezione8-PotQRiter.pdf\n",
            "- (14/21) Indicizzo: 14-Lezione9-JacGasNewtonSistemi.pdf\n",
            "- (15/21) Indicizzo: 15-Ripasso-ODE.pdf\n",
            "- (16/21) Indicizzo: 16-Lezione10-MatlabAlgLin.pdf\n",
            "- (17/21) Indicizzo: 17-Lezione11-InterpAppros.pdf\n",
            "- (18/21) Indicizzo: 18-Lezione12-DerivaIntegra.pdf\n",
            "- (19/21) Indicizzo: 19-Lezione13-Spline.pdf\n",
            "- (20/21) Indicizzo: 20-Lezione14-MatlabInterpAppros.pdf\n",
            "- (21/21) Indicizzo: 21-Lezione15-ODEivp.pdf\n",
            "[FATTO] Indicizzazione: 619 pagine con testo (lette: 619, senza testo: 0).\n"
          ]
        }
      ],
      "source": [
        "# Colab PDF Keyword Search: trova file e pagina nei PDF da parole chiave o frasi\n",
        "# - Scarica i PDF dalla cartella Drive pubblica via gdown (usa il tuo link/ID)\n",
        "# - Indicizza il testo pagina per pagina\n",
        "# - Query con termini e frasi \"tra virgolette\", modalità AND/OR\n",
        "# - Restituisce: file, pagina (1-based), score (occorrenze), matches (dettaglio), snippet di contesto\n",
        "#\n",
        "# NOTE:\n",
        "# - Se la cartella non è pubblica o richiede login, gdown non può scaricare: in quel caso monta Drive e leggi i file direttamente.\n",
        "# - Le pagine senza testo (scansioni) non verranno indicizzate senza OCR.\n",
        "\n",
        "# ===================== INSTALL E IMPORT =====================\n",
        "!pip -q install pdfplumber PyPDF2 gdown pandas\n",
        "\n",
        "import os, re, sys, unicodedata, pickle, json\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "# ===================== CONFIGURAZIONE =====================\n",
        "# Usa gdown con la tua cartella Drive (link fornito)\n",
        "USE_GDOWN = True\n",
        "FOLDER_ID = \"1UxCkCaSzrTfc7qARXUlJ42ta5k2s4qFV\"  # estratto dal tuo link\n",
        "FOLDER_URL = \"\"  # lasciato vuoto perché usiamo FOLDER_ID\n",
        "\n",
        "# Se non vuoi gdown (es. cartella non pubblica), imposta USE_GDOWN=False e monta il tuo Drive:\n",
        "MOUNT_DRIVE = False\n",
        "PDF_DIR = \"/content/drive/MyDrive/PERCORSO/ALLA/TUA/CARTELLA_PDF\"  # usato solo se USE_GDOWN=False\n",
        "\n",
        "# Cache indice\n",
        "INDEX_CACHE_PATH = \"/content/pdf_index_cache.pkl\"\n",
        "\n",
        "# ===================== ACQUISIZIONE FILE =====================\n",
        "if USE_GDOWN:\n",
        "    os.makedirs(\"/content/input_pdfs\", exist_ok=True)\n",
        "    PDF_DIR = \"/content/input_pdfs\"\n",
        "    try:\n",
        "        if FOLDER_ID.strip():\n",
        "            print(\"[INFO] Scarico con gdown usando FOLDER_ID...\")\n",
        "            !gdown --folder --id \"$FOLDER_ID\" -O /content/input_pdfs\n",
        "        elif FOLDER_URL.strip():\n",
        "            print(\"[INFO] Scarico con gdown usando FOLDER_URL...\")\n",
        "            !gdown --folder \"$FOLDER_URL\" -O /content/input_pdfs\n",
        "        else:\n",
        "            raise ValueError(\"Devi impostare FOLDER_ID o FOLDER_URL quando USE_GDOWN=True.\")\n",
        "    except SystemExit:\n",
        "        pass  # gdown può lanciare SystemExit su errori\n",
        "    # Lista rapida\n",
        "    print(\"\\n[CHECK] Contenuto scaricato (prime 100 righe):\")\n",
        "    !ls -R /content/input_pdfs | head -n 100\n",
        "else:\n",
        "    if MOUNT_DRIVE:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "# ===================== UTILITY =====================\n",
        "def normalize_text(s: str) -> str:\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = s.lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
        "    return s\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> List[str]:\n",
        "    \"\"\"Estrae testo per pagina; ritorna lista (una stringa per pagina).\"\"\"\n",
        "    pages = []\n",
        "    try:\n",
        "        import pdfplumber\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                t = page.extract_text() or \"\"\n",
        "                pages.append(t)\n",
        "    except Exception:\n",
        "        try:\n",
        "            import PyPDF2\n",
        "            with open(pdf_path, \"rb\") as f:\n",
        "                reader = PyPDF2.PdfReader(f)\n",
        "                for page in reader.pages:\n",
        "                    t = page.extract_text() or \"\"\n",
        "                    pages.append(t)\n",
        "        except Exception as e2:\n",
        "            print(f\"[AVVISO] Impossibile estrarre testo da {pdf_path}: {e2}\", file=sys.stderr)\n",
        "    return pages\n",
        "\n",
        "def find_pdf_files(root: str) -> List[str]:\n",
        "    pdfs = []\n",
        "    for dirpath, _, filenames in os.walk(root):\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith(\".pdf\"):\n",
        "                pdfs.append(os.path.join(dirpath, fn))\n",
        "    pdfs.sort()\n",
        "    return pdfs\n",
        "\n",
        "def count_substring_occurrences(text: str, sub: str) -> int:\n",
        "    if not sub:\n",
        "        return 0\n",
        "    count = start = 0\n",
        "    while True:\n",
        "        idx = text.find(sub, start)\n",
        "        if idx == -1:\n",
        "            break\n",
        "        count += 1\n",
        "        start = idx + max(1, len(sub))\n",
        "    return count\n",
        "\n",
        "# ===================== INDICIZZATORE =====================\n",
        "@dataclass\n",
        "class PageRecord:\n",
        "    file_path: str\n",
        "    file_name: str\n",
        "    page_num: int   # 1-based\n",
        "    text_norm: str  # normalizzato (lowercase, senza accenti)\n",
        "    text_raw: str   # testo originale (per snippet)\n",
        "\n",
        "class PDFKeywordSearcher:\n",
        "    def __init__(self, pdf_dir: str, cache_path: str = INDEX_CACHE_PATH):\n",
        "        self.pdf_dir = pdf_dir\n",
        "        self.cache_path = cache_path\n",
        "        self.pages: List[PageRecord] = []\n",
        "        self.files_meta: Dict[str, Dict] = {}\n",
        "        self._loaded_from_cache = False\n",
        "\n",
        "    def _current_state_signature(self) -> Dict:\n",
        "        pdfs = find_pdf_files(self.pdf_dir)\n",
        "        meta = {}\n",
        "        for p in pdfs:\n",
        "            try:\n",
        "                st = os.stat(p)\n",
        "                meta[p] = {\"mtime\": st.st_mtime, \"size\": st.st_size}\n",
        "            except FileNotFoundError:\n",
        "                continue\n",
        "        return {\"meta\": meta}\n",
        "\n",
        "    def build_index(self, force_rebuild: bool = False, verbose: bool = True):\n",
        "        sig = self._current_state_signature()\n",
        "\n",
        "        if not force_rebuild and os.path.exists(self.cache_path):\n",
        "            try:\n",
        "                with open(self.cache_path, \"rb\") as f:\n",
        "                    data = pickle.load(f)\n",
        "                if data.get(\"signature\") == sig:\n",
        "                    self.pages = data[\"pages\"]\n",
        "                    self.files_meta = data[\"files_meta\"]\n",
        "                    self._loaded_from_cache = True\n",
        "                    if verbose:\n",
        "                        print(f\"[OK] Indice caricato dalla cache: {len(self.pages)} pagine indicizzate.\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"[INFO] Cache non utilizzabile ({e}), ricostruisco...\")\n",
        "\n",
        "        pdfs = find_pdf_files(self.pdf_dir)\n",
        "        if verbose:\n",
        "            print(f\"[INFO] Trovati {len(pdfs)} PDF in: {self.pdf_dir}\")\n",
        "\n",
        "        pages: List[PageRecord] = []\n",
        "        files_meta = {}\n",
        "        total_pages = 0\n",
        "        empty_pages = 0\n",
        "\n",
        "        for i, pdf in enumerate(pdfs, 1):\n",
        "            try:\n",
        "                st = os.stat(pdf)\n",
        "                files_meta[pdf] = {\"mtime\": st.st_mtime, \"size\": st.st_size}\n",
        "            except FileNotFoundError:\n",
        "                continue\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"- ({i}/{len(pdfs)}) Indicizzo: {os.path.basename(pdf)}\")\n",
        "            page_texts = extract_text_from_pdf(pdf)\n",
        "            for j, raw in enumerate(page_texts, 1):\n",
        "                total_pages += 1\n",
        "                norm = normalize_text(raw)\n",
        "                if not norm.strip():\n",
        "                    empty_pages += 1\n",
        "                    continue  # pagina senza testo (probabile scansione)\n",
        "                pages.append(PageRecord(\n",
        "                    file_path=pdf,\n",
        "                    file_name=os.path.basename(pdf),\n",
        "                    page_num=j,\n",
        "                    text_norm=norm,\n",
        "                    text_raw=raw\n",
        "                ))\n",
        "\n",
        "        self.pages = pages\n",
        "        self.files_meta = files_meta\n",
        "        data = {\"pages\": pages, \"files_meta\": files_meta, \"signature\": sig}\n",
        "        with open(self.cache_path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[FATTO] Indicizzazione: {len(self.pages)} pagine con testo\"\n",
        "                  f\" (lette: {total_pages}, senza testo: {empty_pages}).\")\n",
        "            if empty_pages > 0:\n",
        "                print(\"[NOTA] Alcune pagine erano senza testo (scansioni). Per indicizzarle serve OCR (es. Tesseract).\")\n",
        "\n",
        "    def _parse_query(self, query: str) -> Tuple[List[str], List[str]]:\n",
        "        qn = normalize_text(query)\n",
        "        phrases = re.findall(r'\"([^\"]+)\"', qn)               # frasi tra virgolette\n",
        "        qn_wo_phrases = re.sub(r'\"[^\"]+\"', \" \", qn)          # rimuovi frasi\n",
        "        terms = [t for t in re.split(r\"\\s+\", qn_wo_phrases) if t]\n",
        "        return phrases, terms\n",
        "\n",
        "    def _build_term_patterns(self, terms: List[str]) -> Dict[str, re.Pattern]:\n",
        "        patterns = {}\n",
        "        for term in terms:\n",
        "            try:\n",
        "                patterns[term] = re.compile(rf\"\\b{re.escape(term)}\\b\")\n",
        "            except re.error:\n",
        "                patterns[term] = re.compile(re.escape(term))\n",
        "        return patterns\n",
        "\n",
        "    def _first_hit_position(self, text_norm: str, term_patterns: Dict[str, re.Pattern], phrases: List[str]) -> int:\n",
        "        pos = []\n",
        "        for _, pat in term_patterns.items():\n",
        "            m = pat.search(text_norm)\n",
        "            if m: pos.append(m.start())\n",
        "        for ph in phrases:\n",
        "            i = text_norm.find(ph)\n",
        "            if i != -1: pos.append(i)\n",
        "        return min(pos) if pos else -1\n",
        "\n",
        "    def _make_snippet(self, text_norm: str, center_pos: int, context_chars: int = 100) -> str:\n",
        "        if center_pos < 0:\n",
        "            center_pos = 0\n",
        "        start = max(0, center_pos - context_chars)\n",
        "        end = min(len(text_norm), center_pos + context_chars)\n",
        "        prefix = \"...\" if start > 0 else \"\"\n",
        "        suffix = \"...\" if end < len(text_norm) else \"\"\n",
        "        return prefix + text_norm[start:end].replace(\"\\n\", \" \") + suffix\n",
        "\n",
        "    def search(self, query: str, match_mode: str = \"AND\", max_results: int = 100, context_chars: int = 100) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        match_mode: \"AND\" richiede che ogni termine/frase compaia nella pagina; \"OR\" almeno uno.\n",
        "        \"\"\"\n",
        "        if not self.pages:\n",
        "            raise RuntimeError(\"Indice vuoto. Esegui prima build_index().\")\n",
        "\n",
        "        phrases, terms = self._parse_query(query)\n",
        "        term_patterns = self._build_term_patterns(terms)\n",
        "\n",
        "        rows = []\n",
        "        for rec in self.pages:\n",
        "            text = rec.text_norm\n",
        "\n",
        "            counts: Dict[str, int] = {}\n",
        "            total = 0\n",
        "\n",
        "            for t, pat in term_patterns.items():\n",
        "                c = len(pat.findall(text))\n",
        "                counts[t] = c\n",
        "                total += c\n",
        "\n",
        "            for ph in phrases:\n",
        "                c = count_substring_occurrences(text, ph)\n",
        "                counts[f'\"{ph}\"'] = c\n",
        "                total += c\n",
        "\n",
        "            if match_mode.upper() == \"AND\":\n",
        "                needed = list(terms) + [f'\"{ph}\"' for ph in phrases]\n",
        "                if any(counts.get(k, 0) == 0 for k in needed):\n",
        "                    continue\n",
        "                if total == 0:\n",
        "                    continue\n",
        "            else:\n",
        "                if total == 0:\n",
        "                    continue\n",
        "\n",
        "            pos = self._first_hit_position(text, term_patterns, phrases)\n",
        "            snippet = self._make_snippet(text, pos, context_chars=context_chars)\n",
        "\n",
        "            rows.append({\n",
        "                \"file\": rec.file_path,\n",
        "                \"file_name\": rec.file_name,\n",
        "                \"page\": rec.page_num,\n",
        "                \"score\": int(total),\n",
        "                \"matches\": json.dumps({k: int(v) for k, v in counts.items() if v > 0}, ensure_ascii=False),\n",
        "                \"snippet_norm\": snippet\n",
        "            })\n",
        "\n",
        "        if not rows:\n",
        "            return pd.DataFrame(columns=[\"file\", \"file_name\", \"page\", \"score\", \"matches\", \"snippet_norm\"])\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.sort_values(by=[\"score\", \"file_name\", \"page\"], ascending=[False, True, True], inplace=True)\n",
        "        if max_results and max_results > 0:\n",
        "            df = df.head(max_results).reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "# ===================== AVVIO: CHECK + INDICIZZAZIONE =====================\n",
        "print(f\"[CHECK] PDF_DIR: {PDF_DIR}\")\n",
        "if not os.path.exists(PDF_DIR):\n",
        "    print(\"[ERRORE] La cartella PDF_DIR non esiste. Se gdown ha fallito, rendi pubblica la cartella o usa il mount Drive (USE_GDOWN=False).\")\n",
        "else:\n",
        "    pdfs = find_pdf_files(PDF_DIR)\n",
        "    print(f\"[CHECK] PDF trovati: {len(pdfs)}\")\n",
        "    for p in pdfs[:10]:\n",
        "        print(\" -\", p)\n",
        "\n",
        "searcher = PDFKeywordSearcher(PDF_DIR, cache_path=INDEX_CACHE_PATH)\n",
        "searcher.build_index(force_rebuild=False, verbose=True)\n",
        "\n",
        "# ===================== ESEMPI DI QUERY =====================\n",
        "# Esempio 1 (OR): almeno uno dei termini\n",
        "# df = searcher.search('newton \"pivot parziale\"', match_mode=\"OR\", max_results=50)\n",
        "# display(df.head(20))\n",
        "\n",
        "# Esempio 2 (AND): tutti i termini/frasi devono comparire\n",
        "# df = searcher.search('gauss cholesky', match_mode=\"AND\", max_results=100)\n",
        "# with pd.option_context('display.max_colwidth', 120):\n",
        "#     display(df.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    q = input(\"Query (invio per uscire): \").strip()\n",
        "    if not q:\n",
        "        break\n",
        "    mode = (input(\"Modalità (AND/OR) [AND]: \").strip() or \"AND\").upper()\n",
        "    df = searcher.search(q, match_mode=mode, max_results=50)\n",
        "    with pd.option_context('display.max_colwidth', 120):\n",
        "        display(df.head(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "esmBgYGzpAdB",
        "outputId": "7d792d71-921d-4f1d-bdaf-cd9402148022"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1807688012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query (invio per uscire): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Modalità (AND/OR) [AND]: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"AND\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}